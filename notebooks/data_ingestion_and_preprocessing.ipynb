{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8db71c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\yohanan\\amharic-e-commerce-data-extractor\\.venv\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\yohanan\\amharic-e-commerce-data-extractor\\.venv\\lib\\site-packages (from pandas) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yohanan\\amharic-e-commerce-data-extractor\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yohanan\\amharic-e-commerce-data-extractor\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yohanan\\amharic-e-commerce-data-extractor\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yohanan\\amharic-e-commerce-data-extractor\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: telethon in c:\\users\\yohanan\\amharic-e-commerce-data-extractor\\.venv\\lib\\site-packages (1.40.0)\n",
      "Requirement already satisfied: pyaes in c:\\users\\yohanan\\amharic-e-commerce-data-extractor\\.venv\\lib\\site-packages (from telethon) (1.6.1)\n",
      "Requirement already satisfied: rsa in c:\\users\\yohanan\\amharic-e-commerce-data-extractor\\.venv\\lib\\site-packages (from telethon) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\yohanan\\amharic-e-commerce-data-extractor\\.venv\\lib\\site-packages (from rsa->telethon) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: Pillow in c:\\users\\yohanan\\amharic-e-commerce-data-extractor\\.venv\\lib\\site-packages (11.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-magic-bin in c:\\users\\yohanan\\amharic-e-commerce-data-extractor\\.venv\\lib\\site-packages (0.4.14)\n",
      "Requirement already satisfied: numpy in c:\\users\\yohanan\\amharic-e-commerce-data-extractor\\.venv\\lib\\site-packages (2.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: telethon in c:\\users\\yohanan\\amharic-e-commerce-data-extractor\\.venv\\lib\\site-packages (1.40.0)\n",
      "Requirement already satisfied: pyaes in c:\\users\\yohanan\\amharic-e-commerce-data-extractor\\.venv\\lib\\site-packages (from telethon) (1.6.1)\n",
      "Requirement already satisfied: rsa in c:\\users\\yohanan\\amharic-e-commerce-data-extractor\\.venv\\lib\\site-packages (from telethon) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\yohanan\\amharic-e-commerce-data-extractor\\.venv\\lib\\site-packages (from rsa->telethon) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Fetching messages from @ZemenExpress...\n",
      "Error accessing channel @ZemenExpress: You must use \"async for\" if the event loop is running (i.e. you are inside an \"async def\")\n",
      "Saved 0 records to processed_data\\@ZemenExpress_messages.csv\n",
      "Fetching messages from @nevacomputer...\n",
      "Error accessing channel @nevacomputer: You must use \"async for\" if the event loop is running (i.e. you are inside an \"async def\")\n",
      "Saved 0 records to processed_data\\@nevacomputer_messages.csv\n",
      "Fetching messages from @meneshayeofficial...\n",
      "Error accessing channel @meneshayeofficial: You must use \"async for\" if the event loop is running (i.e. you are inside an \"async def\")\n",
      "Saved 0 records to processed_data\\@meneshayeofficial_messages.csv\n",
      "Fetching messages from @ethio_brand_collection...\n",
      "Error accessing channel @ethio_brand_collection: You must use \"async for\" if the event loop is running (i.e. you are inside an \"async def\")\n",
      "Saved 0 records to processed_data\\@ethio_brand_collection_messages.csv\n",
      "Fetching messages from @Leyueqa@AwasMart...\n",
      "Error accessing channel @Leyueqa@AwasMart: You must use \"async for\" if the event loop is running (i.e. you are inside an \"async def\")\n",
      "Saved 0 records to processed_data\\@Leyueqa@AwasMart_messages.csv\n",
      "Data collection complete!\n",
      "Fetching messages from @ZemenExpress...\n",
      "Error accessing channel @ZemenExpress: You must use \"async for\" if the event loop is running (i.e. you are inside an \"async def\")\n",
      "Saved 0 records to processed_data\\@ZemenExpress_messages.csv\n",
      "Fetching messages from @nevacomputer...\n",
      "Error accessing channel @nevacomputer: You must use \"async for\" if the event loop is running (i.e. you are inside an \"async def\")\n",
      "Saved 0 records to processed_data\\@nevacomputer_messages.csv\n",
      "Fetching messages from @meneshayeofficial...\n",
      "Error accessing channel @meneshayeofficial: You must use \"async for\" if the event loop is running (i.e. you are inside an \"async def\")\n",
      "Saved 0 records to processed_data\\@meneshayeofficial_messages.csv\n",
      "Fetching messages from @ethio_brand_collection...\n",
      "Error accessing channel @ethio_brand_collection: You must use \"async for\" if the event loop is running (i.e. you are inside an \"async def\")\n",
      "Saved 0 records to processed_data\\@ethio_brand_collection_messages.csv\n",
      "Fetching messages from @Leyueqa@AwasMart...\n",
      "Error accessing channel @Leyueqa@AwasMart: You must use \"async for\" if the event loop is running (i.e. you are inside an \"async def\")\n",
      "Saved 0 records to processed_data\\@Leyueqa@AwasMart_messages.csv\n",
      "Data collection complete!\n",
      "Scraping complete!\n",
      "Warning: 'text' column not found in DataFrame. Returning empty DataFrame.\n",
      "Processed data saved to fully_processed_data.csv\n",
      "Data preprocessing complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yohanan\\AppData\\Local\\Temp\\ipykernel_10580\\803935812.py:43: RuntimeWarning: coroutine 'AuthMethods._start' was never awaited\n",
      "  self.client.start(PHONE_NUMBER)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\Yohanan\\AppData\\Local\\Temp\\ipykernel_10580\\803935812.py:224: RuntimeWarning: coroutine 'UserMethods.get_entity' was never awaited\n",
      "  channel_messages = self.fetch_channel_messages(channel)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\Yohanan\\AppData\\Local\\Temp\\ipykernel_10580\\803935812.py:224: RuntimeWarning: coroutine 'UserMethods.get_entity' was never awaited\n",
      "  channel_messages = self.fetch_channel_messages(channel)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\Yohanan\\AppData\\Local\\Temp\\ipykernel_10580\\803935812.py:224: RuntimeWarning: coroutine 'UserMethods.get_entity' was never awaited\n",
      "  channel_messages = self.fetch_channel_messages(channel)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\Yohanan\\AppData\\Local\\Temp\\ipykernel_10580\\803935812.py:224: RuntimeWarning: coroutine 'UserMethods.get_entity' was never awaited\n",
      "  channel_messages = self.fetch_channel_messages(channel)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\Yohanan\\AppData\\Local\\Temp\\ipykernel_10580\\803935812.py:224: RuntimeWarning: coroutine 'UserMethods.get_entity' was never awaited\n",
      "  channel_messages = self.fetch_channel_messages(channel)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\Yohanan\\AppData\\Local\\Temp\\ipykernel_10580\\803935812.py:43: RuntimeWarning: coroutine 'AuthMethods._start' was never awaited\n",
      "  self.client.start(PHONE_NUMBER)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\Yohanan\\AppData\\Local\\Temp\\ipykernel_10580\\803935812.py:224: RuntimeWarning: coroutine 'UserMethods.get_entity' was never awaited\n",
      "  channel_messages = self.fetch_channel_messages(channel)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\Yohanan\\AppData\\Local\\Temp\\ipykernel_10580\\803935812.py:224: RuntimeWarning: coroutine 'UserMethods.get_entity' was never awaited\n",
      "  channel_messages = self.fetch_channel_messages(channel)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\Yohanan\\AppData\\Local\\Temp\\ipykernel_10580\\803935812.py:224: RuntimeWarning: coroutine 'UserMethods.get_entity' was never awaited\n",
      "  channel_messages = self.fetch_channel_messages(channel)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\Yohanan\\AppData\\Local\\Temp\\ipykernel_10580\\803935812.py:224: RuntimeWarning: coroutine 'UserMethods.get_entity' was never awaited\n",
      "  channel_messages = self.fetch_channel_messages(channel)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\Yohanan\\AppData\\Local\\Temp\\ipykernel_10580\\803935812.py:224: RuntimeWarning: coroutine 'UserMethods.get_entity' was never awaited\n",
      "  channel_messages = self.fetch_channel_messages(channel)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install telethon \n",
    "%pip install Pillow \n",
    "%pip install python-magic-bin numpy\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "%pip install telethon\n",
    "from telethon import TelegramClient\n",
    "from telethon.tl.types import MessageMediaPhoto, MessageMediaDocument\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import magic\n",
    "from collections import defaultdict\n",
    "\n",
    "# Configuration\n",
    "API_ID = '20456758'  # Replace with your API ID\n",
    "API_HASH = '83bb06a8c677ed8128784c2dc575aff6'  # Replace with your API hash\n",
    "PHONE_NUMBER = '+251920747086'  # Replace with your phone number\n",
    "SESSION_NAME = 'amharic_ecommerce_scraper'\n",
    "# List of Ethiopian e-commerce channels to monitor\n",
    "CHANNELS = [\n",
    "    '@ZemenExpress',          \n",
    "    '@nevacomputer',    \n",
    "    '@meneshayeofficial',\n",
    "    '@ethio_brand_collection',       \n",
    "    '@Leyueqa' \n",
    "    '@AwasMart',    \n",
    "]\n",
    "# Output directories\n",
    "RAW_DATA_DIR = 'raw_data'\n",
    "PROCESSED_DATA_DIR = 'processed_data'\n",
    "IMAGES_DIR = os.path.join(RAW_DATA_DIR, 'images')\n",
    "os.makedirs(RAW_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "class TelegramScraper:\n",
    "    def __init__(self):\n",
    "        self.client = TelegramClient(SESSION_NAME, API_ID, API_HASH)\n",
    "        self.client.start(PHONE_NUMBER)\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Main execution method\"\"\"\n",
    "        all_messages = []\n",
    "        \n",
    "        # Fetch messages from all channels\n",
    "        for channel in CHANNELS:\n",
    "            channel_messages = self.fetch_channel_messages(channel)\n",
    "            all_messages.extend(channel_messages)\n",
    "            \n",
    "            # Save individual channel data\n",
    "            self.save_to_csv(channel_messages, f'{channel}_messages.csv')\n",
    "        \n",
    "        # Save combined data\n",
    "        if all_messages:\n",
    "            self.save_to_csv(all_messages, 'all_channels_combined.csv')\n",
    "        \n",
    "        print(\"Data collection complete!\")    \n",
    "    def clean_amharic_text(self, text):\n",
    "        \"\"\"\n",
    "        Clean and normalize Amharic text\n",
    "        \"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "# Remove URLs\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "        \n",
    "        # Remove emojis and special characters (keeping Amharic characters)\n",
    "        # Amharic Unicode range: U+1200 to U+137F\n",
    "        text = re.sub(r'[^\\u1200-\\u137F\\s.,!?።፣፤፥፦፧፨0-9a-zA-Z]', '', text)\n",
    "        \n",
    "        # Normalize whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    def extract_entities(self, text):\n",
    "        \"\"\"\n",
    "        Basic entity extraction for Amharic e-commerce text\n",
    "        \"\"\"\n",
    "        entities = {\n",
    "            'prices': [],\n",
    "            'products': [],\n",
    "            'locations': [],\n",
    "            'contacts': []\n",
    "        }\n",
    "        \n",
    "        if not text:\n",
    "            return entities\n",
    "        \n",
    "        # Extract prices (numbers with currency symbols or words)\n",
    "        price_patterns = [\n",
    "            r'(\\d+)\\s*(ብር|br|birr|BR|ብሮ|ብሬ)',  # Ethiopian Birr\n",
    "            r'\\$\\s*(\\d+)',                      # US Dollars\n",
    "            r'(\\d+)\\s*(ዶላር|dollar)'             # Dollars in Amharic\n",
    "        ]\n",
    "        \n",
    "        for pattern in price_patterns:\n",
    "            matches = re.findall(pattern, text)\n",
    "            for match in matches:\n",
    "                if match[0].isdigit():\n",
    "                    entities['prices'].append(match[0] + ' ' + (match[1] if len(match) > 1 else 'ብር'))\n",
    "        \n",
    "        # Extract phone numbers (Ethiopian format)\n",
    "        phone_matches = re.findall(r'(?:\\+251|0)(?:9\\d{8}|[1-9]\\d{7})', text)\n",
    "        entities['contacts'].extend(phone_matches)\n",
    "        \n",
    "        # Extract locations (common Ethiopian cities/areas)\n",
    "        locations = ['አዲስ አበባ', 'ባህር �ር', 'ድሬ ዳዋ', 'ጅማ', 'መቀሌ', \n",
    "                    'አዋሳ', 'አርባ ምንጭ', 'አዲስ አበባ', 'ባህር ዳር', 'ጎንደር']\n",
    "        entities['locations'] = [loc for loc in locations if loc in text]\n",
    "        \n",
    "        return entities\n",
    "    \n",
    "    def download_media(self, message):\n",
    "        \"\"\"\n",
    "        Download and process media files (images, documents)\n",
    "        \"\"\"\n",
    "        media_info = {\n",
    "            'media_type': None,\n",
    "            'file_path': None,\n",
    "            'file_size': None,\n",
    "            'dimensions': None\n",
    "        }\n",
    "        \n",
    "        if not message.media:\n",
    "            return media_info\n",
    "        \n",
    "        try:\n",
    "            if isinstance(message.media, MessageMediaPhoto):\n",
    "                # Download photo\n",
    "                media_info['media_type'] = 'photo'\n",
    "                file_path = os.path.join(IMAGES_DIR, f'photo_{message.id}.jpg')\n",
    "                self.client.download_media(message.media, file=file_path)\n",
    "                \n",
    "                # Get image dimensions\n",
    "                with Image.open(file_path) as img:\n",
    "                    media_info['dimensions'] = f\"{img.width}x{img.height}\"\n",
    "                \n",
    "                media_info['file_path'] = file_path\n",
    "                media_info['file_size'] = os.path.getsize(file_path)\n",
    "                \n",
    "            elif isinstance(message.media, MessageMediaDocument):\n",
    "                # Download document\n",
    "                media_info['media_type'] = 'document'\n",
    "                file_name = f'document_{message.id}'\n",
    "                file_path = os.path.join(RAW_DATA_DIR, file_name)\n",
    "                self.client.download_media(message.media, file=file_path)\n",
    "                \n",
    "                # Get file type\n",
    "                mime = magic.Magic(mime=True)\n",
    "                file_type = mime.from_file(file_path)\n",
    "                \n",
    "                # Rename file with proper extension\n",
    "                ext = file_type.split('/')[-1]\n",
    "                new_path = f\"{file_path}.{ext}\"\n",
    "                os.rename(file_path, new_path)\n",
    "                \n",
    "                media_info['file_path'] = new_path\n",
    "                media_info['file_size'] = os.path.getsize(new_path)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading media: {e}\")\n",
    "        \n",
    "        return media_info\n",
    "    \n",
    "    def fetch_channel_messages(self, channel_name, limit=1000):\n",
    "        \"\"\"\n",
    "        Fetch messages from a Telegram channel\n",
    "        \"\"\"\n",
    "        print(f\"Fetching messages from {channel_name}...\")\n",
    "        \n",
    "        messages_data = []\n",
    "        try:\n",
    "            channel = self.client.get_entity(channel_name)\n",
    "            \n",
    "            for message in self.client.iter_messages(channel, limit=limit):\n",
    "                try:\n",
    "                    # Basic message info\n",
    "                    msg_data = {\n",
    "                        'channel': channel_name,\n",
    "                        'message_id': message.id,\n",
    "                        'date': message.date,\n",
    "                        'text': self.clean_amharic_text(message.text),\n",
    "                        'views': message.views if hasattr(message, 'views') else None,\n",
    "                        'sender': message.sender_id if hasattr(message, 'sender_id') else None\n",
    "                    }\n",
    "                    \n",
    "                    # Download and process media\n",
    "                    media_info = self.download_media(message)\n",
    "                    msg_data.update(media_info)\n",
    "                    \n",
    "                    # Extract entities from text\n",
    "                    entities = self.extract_entities(message.text)\n",
    "                    msg_data.update(entities)\n",
    "                    \n",
    "                    messages_data.append(msg_data)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing message {message.id}: {e}\")\n",
    "                    continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error accessing channel {channel_name}: {e}\")\n",
    "        \n",
    "        return messages_data\n",
    "    \n",
    "    def save_to_csv(self, data, filename):\n",
    "        \"\"\"Save data to CSV file\"\"\"\n",
    "        df = pd.DataFrame(data)\n",
    "        filepath = os.path.join(PROCESSED_DATA_DIR, filename)\n",
    "        df.to_csv(filepath, index=False, encoding='utf-8')\n",
    "        print(f\"Saved {len(df)} records to {filepath}\")\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"Main execution method\"\"\"\n",
    "        all_messages = []\n",
    "        \n",
    "        # Fetch messages from all channels\n",
    "        for channel in CHANNELS:\n",
    "            channel_messages = self.fetch_channel_messages(channel)\n",
    "            all_messages.extend(channel_messages)\n",
    "            \n",
    "            # Save individual channel data\n",
    "            self.save_to_csv(channel_messages, f'{channel}_messages.csv')\n",
    "        \n",
    "        # Save combined data\n",
    "        if all_messages:\n",
    "            self.save_to_csv(all_messages, 'all_channels_combined.csv')\n",
    "        \n",
    "        print(\"Data collection complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scraper = TelegramScraper()\n",
    "    scraper.run()\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, raw_data_dir):\n",
    "        self.raw_data_dir = raw_data_dir\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load all CSV files from the raw data directory, skipping empty files\"\"\"\n",
    "        all_data = []\n",
    "        for file in os.listdir(self.raw_data_dir):\n",
    "            if file.endswith('.csv'):\n",
    "                filepath = os.path.join(self.raw_data_dir, file)\n",
    "                try:\n",
    "                    df = pd.read_csv(filepath, encoding='utf-8')\n",
    "                    if not df.empty:\n",
    "                        all_data.append(df)\n",
    "                except pd.errors.EmptyDataError:\n",
    "                    print(f\"Skipped empty file: {filepath}\")\n",
    "        \n",
    "        if all_data:\n",
    "            return pd.concat(all_data, ignore_index=True)\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Advanced text preprocessing for Amharic\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Remove repeated characters (common in informal text)\n",
    "        text = re.sub(r'(.)\\1{2,}', r'\\1', text)\n",
    "        \n",
    "        # Normalize Amharic numbers to Western numerals\n",
    "        amharic_numerals = {\n",
    "            '፩': '1', '፪': '2', '፫': '3', '፬': '4', '፭': '5',\n",
    "            '፮': '6', '፯': '7', '፰': '8', '፱': '9', '፲': '10'\n",
    "        }\n",
    "        \n",
    "        for am_num, num in amharic_numerals.items():\n",
    "            text = text.replace(am_num, num)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def process_data(self, df):\n",
    "        \"\"\"\n",
    "        Process the raw dataframe\n",
    "        \"\"\"\n",
    "        # Check if 'text' column exists\n",
    "        if 'text' not in df.columns:\n",
    "            print(\"Warning: 'text' column not found in DataFrame. Returning empty DataFrame.\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Clean text\n",
    "        df['clean_text'] = df['text'].apply(self.preprocess_text)\n",
    "        \n",
    "        # Convert date to datetime if 'date' column exists\n",
    "        if 'date' in df.columns:\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "        \n",
    "        # Extract additional features\n",
    "        df['text_length'] = df['clean_text'].apply(len)\n",
    "        df['word_count'] = df['clean_text'].apply(lambda x: len(x.split()))\n",
    "        \n",
    "        # Handle missing values for expected columns\n",
    "        for col in ['prices', 'locations', 'contacts']:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].fillna('[]')\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def save_processed_data(self, df, output_file):\n",
    "        \"\"\"Save processed data to file\"\"\"\n",
    "        df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "        print(f\"Processed data saved to {output_file}\")\n",
    "# ...existing code...\n",
    "if __name__ == \"__main__\":\n",
    "    scraper = TelegramScraper()\n",
    "    scraper.run()\n",
    "    print(\"Scraping complete!\")\n",
    "    preprocessor = DataPreprocessor(RAW_DATA_DIR)  # <-- use RAW_DATA_DIR here\n",
    "    raw_data = preprocessor.load_data()\n",
    "    processed_data = preprocessor.process_data(raw_data)\n",
    "    preprocessor.save_processed_data(processed_data, 'fully_processed_data.csv')\n",
    "    print(\"Data preprocessing complete!\")\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
